{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking different CF explanation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show runtimes of different model-agnostic explanation methods. Currently, we support three model-agnostic explanation methods:\n",
    "1. Random-Sampling\n",
    "2. Genetic Algorithm\n",
    "3. Querying a KD tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import random\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from dice_ml.explainer_interfaces.dice_genetic import DiceGenetic\n",
    "from dice_ml.explainer_interfaces.dice_KD import DiceKD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the \"adult\" income dataset from UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/adult). For demonstration purposes, we transform the data as described in dice_ml.utils.helpers module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = helpers.load_adult_income_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Government</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age      workclass  education marital_status    occupation   race  gender  \\\n",
       "0   39     Government  Bachelors         Single  White-Collar  White    Male   \n",
       "1   50  Self-Employed  Bachelors        Married  White-Collar  White    Male   \n",
       "2   38        Private    HS-grad       Divorced   Blue-Collar  White    Male   \n",
       "3   53        Private     School        Married   Blue-Collar  Other    Male   \n",
       "4   28        Private  Bachelors        Married  Professional  Other  Female   \n",
       "\n",
       "   hours_per_week  income  \n",
       "0              40       0  \n",
       "1              13       0  \n",
       "2              40       0  \n",
       "3              40       0  \n",
       "4              40       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the genetic algorithm & KD tree methods work with scikit-learn models. Support for Tensorflow 1&2 and Pytorch will be implemented soon.\n",
    "\n",
    "We train two sklearn MLP's here: one by one-hot-encoding the categorical variables, and another by label-encoding the categorical variables. This is done because the random-sampling and DiceKD explanation methods use one-hot encoding, while DiceGenetic explanation method uses label-encoding. We plan to support other types of encoding in the near future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe, test_ohe = d.split_data(d.normalize_data(d.one_hot_encoded_data))\n",
    "X_train_ohe = train_ohe.loc[:, train_ohe.columns != 'income']\n",
    "y_train_ohe = train_ohe.loc[:, train_ohe.columns == 'income']\n",
    "X_test_ohe = test_ohe.loc[:, test_ohe.columns != 'income']\n",
    "y_test_ohe = test_ohe.loc[:, test_ohe.columns == 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soundaryakrishnan/opt/anaconda2/envs/dice_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, batch_size=32, hidden_layer_sizes=20,\n",
       "              learning_rate_init=0.01, max_iter=20, random_state=17,\n",
       "              validation_fraction=0.2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_ohe = MLPClassifier(hidden_layer_sizes=(20), alpha=0.001, learning_rate_init=0.01, batch_size=32, random_state=17,\n",
    "                    max_iter=20, verbose=False, validation_fraction=0.2, ) #max_iter is epochs in TF\n",
    "mlp_ohe.fit(X_train_ohe, y_train_ohe.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the trained ML model to DiCE's model object\n",
    "m_ohe = dice_ml.Model(model=mlp_ohe, backend=backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lbl, test_lbl = d.split_data(d.normalize_data(d.label_encoded_data))\n",
    "X_train_lbl = train_lbl.loc[:, train_lbl.columns != 'income']\n",
    "y_train_lbl = train_lbl.loc[:, train_lbl.columns == 'income']\n",
    "X_test_lbl = test_lbl.loc[:, test_lbl.columns != 'income']\n",
    "y_test_lbl = test_lbl.loc[:, test_lbl.columns == 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soundaryakrishnan/opt/anaconda2/envs/dice_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, batch_size=32, hidden_layer_sizes=20,\n",
       "              learning_rate_init=0.01, max_iter=20, random_state=17,\n",
       "              validation_fraction=0.2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_lbl = MLPClassifier(hidden_layer_sizes=(20), alpha=0.001, learning_rate_init=0.01, batch_size=32, random_state=17,\n",
    "                    max_iter=20, verbose=False, validation_fraction=0.2, ) #max_iter is epochs in TF\n",
    "mlp_lbl.fit(X_train_lbl, y_train_lbl.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the trained ML model to DiCE's model object\n",
    "m_lbl = dice_ml.Model(model=mlp_lbl, backend=backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize counterfactual generation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize all three counterfactuals generation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = dice_ml.Dice(d, m_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_genetic = DiceGenetic(d, m_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_KD = DiceKD(d, m_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance = {'age':22, \n",
    "                  'workclass':'Private', \n",
    "                  'education':'HS-grad', \n",
    "                  'marital_status':'Single', \n",
    "                  'occupation':'Service',\n",
    "                  'race': 'White', \n",
    "                  'gender':'Female', \n",
    "                  'hours_per_week': 45}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate counterfactuals using all three different methods and check the runtime. You can modify the number of loops (```num_loops```), and the number of diverse counterfactuals to generate (```k```). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_loops = 10\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Independent random sampling of features: Total time taken to generate 10 sets of 3 counterfactuals each: 00 min 01 sec\n",
      "For querying from a KD tree: Total time taken to generate 10 sets of 3 counterfactuals each: 00 min 01 sec\n",
      "For genetic algorithm: Total time taken to generate 10 sets of 3 counterfactuals each: 00 min 01 sec\n"
     ]
    }
   ],
   "source": [
    "elapsed_random = 0\n",
    "elapsed_kd = 0\n",
    "elapsed_genetic = 0\n",
    "\n",
    "for i in range(num_loops):    \n",
    "    for q in query_instance:\n",
    "        if q in d.categorical_feature_names:\n",
    "            query_instance[q] = random.choice(dataset[q].values.unique())\n",
    "        else:\n",
    "            query_instance[q] = np.random.uniform(dataset[q].min(), dataset[q].max())\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=k, desired_class=\"opposite\", verbose=False)\n",
    "    elapsed_random += timeit.default_timer() - start_time    \n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    dice_exp = exp_genetic.generate_counterfactuals(query_instance, total_CFs=k, desired_class=\"opposite\", yloss_type=\"hinge_loss\", verbose=False)\n",
    "    elapsed_genetic += timeit.default_timer() - start_time  \n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    dice_kd = exp_KD.generate_counterfactuals(query_instance, total_CFs=k, desired_class=\"opposite\", verbose=False)\n",
    "    elapsed_kd += timeit.default_timer() - start_time  \n",
    "    \n",
    "m_random, s_random = divmod(elapsed_random, 60)\n",
    "print('For Independent random sampling of features: Total time taken to generate %d' %num_loops, 'sets of %d' %k, 'counterfactuals each: %02d' %m_random, 'min %02d' % s_random, 'sec')\n",
    "\n",
    "m_kd, s_kd = divmod(elapsed_kd, 60)\n",
    "print('For querying from a KD tree: Total time taken to generate %d' %num_loops, 'sets of %d' %k, 'counterfactuals each: %02d' %m_kd, 'min %02d' % s_kd, 'sec')\n",
    "\n",
    "m_genetic, s_genetic = divmod(elapsed_genetic, 60)\n",
    "print('For genetic algorithm: Total time taken to generate %d' %num_loops, 'sets of %d' %k, 'counterfactuals each: %02d' %m_genetic, 'min %02d' % s_genetic, 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dice_env",
   "language": "python",
   "name": "dice_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
